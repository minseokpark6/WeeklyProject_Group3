{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ciw96\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ciw96\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import font_manager, rc\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import chardet\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# nltk 데이터 다운로드 (첫 실행 시 필요)\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# nltk 데이터 다운로드 (첫 실행 시 필요)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 글꼴 경로 지정\n",
    "font_path = \"c:/Windows/Fonts/malgun.ttf\"  # 윈도우에 설치된 맑은 고딕 폰트 경로\n",
    "\n",
    "# 폰트 이름 얻어오기\n",
    "font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "\n",
    "# matplotlib의 rc(run command) 기능을 이용하여 글꼴 설정\n",
    "mpl.rc('font', family=font_name)\n",
    "\n",
    "# 유니코드에서  음수 부호 설정\n",
    "mpl.rc('axes', unicode_minus=False)\n",
    "\n",
    "raw = pd.read_csv('../../../../../datasets/paris_reviews_check1.csv')\n",
    "df = raw.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw[raw['is_english']==False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>숙소_id</th>\n",
       "      <th>리뷰날짜</th>\n",
       "      <th>리뷰</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>부정</th>\n",
       "      <th>중립</th>\n",
       "      <th>긍정</th>\n",
       "      <th>전체</th>\n",
       "      <th>is_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2104349</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>Strategically positioned apartment (in two lev...</td>\n",
       "      <td>{'neg': 0.01, 'neu': 0.842, 'pos': 0.148, 'com...</td>\n",
       "      <td>0.307619</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>904241734383540468</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>Beautiful place. one bedroom with a bedsofa in...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...</td>\n",
       "      <td>0.375040</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23476199</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>Alexandra's apartment is like a trip back in t...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.69, 'pos': 0.31, 'compou...</td>\n",
       "      <td>0.277292</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>723879972115619669</td>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>Wonderful apartment, felt right at home.  Love...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.571, 'pos': 0.429, 'comp...</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25025384</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>Good place, close to train station! Alex is ve...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.494, 'pos': 0.506, 'comp...</td>\n",
       "      <td>0.655938</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                숙소_id        리뷰날짜  \\\n",
       "0             2104349  2019-03-03   \n",
       "1  904241734383540468  2023-09-09   \n",
       "2            23476199  2018-05-29   \n",
       "3  723879972115619669  2022-12-02   \n",
       "4            25025384  2022-04-29   \n",
       "\n",
       "                                                  리뷰  \\\n",
       "0  Strategically positioned apartment (in two lev...   \n",
       "1  Beautiful place. one bedroom with a bedsofa in...   \n",
       "2  Alexandra's apartment is like a trip back in t...   \n",
       "3  Wonderful apartment, felt right at home.  Love...   \n",
       "4  Good place, close to train station! Alex is ve...   \n",
       "\n",
       "                                     vader_sentiment  textblob_sentiment  \\\n",
       "0  {'neg': 0.01, 'neu': 0.842, 'pos': 0.148, 'com...            0.307619   \n",
       "1  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...            0.375040   \n",
       "2  {'neg': 0.0, 'neu': 0.69, 'pos': 0.31, 'compou...            0.277292   \n",
       "3  {'neg': 0.0, 'neu': 0.571, 'pos': 0.429, 'comp...            0.471429   \n",
       "4  {'neg': 0.0, 'neu': 0.494, 'pos': 0.506, 'comp...            0.655938   \n",
       "\n",
       "     부정     중립     긍정      전체  is_english  \n",
       "0  0.01  0.842  0.148  0.9701        True  \n",
       "1  0.00  0.769  0.231  0.6908        True  \n",
       "2  0.00  0.690  0.310  0.9622        True  \n",
       "3  0.00  0.571  0.429  0.8176        True  \n",
       "4  0.00  0.494  0.506  0.9609        True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ciw96\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "c:\\Users\\ciw96\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# nltk 토크나이저 로드\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 데이터 로딩\n",
    "df = pd.read_csv('../../../../../datasets/paris_reviews_check1.csv')\n",
    "df = df[['숙소_id', '리뷰날짜', '리뷰']]\n",
    "\n",
    "# 전처리: 영어와 공백만 남김\n",
    "df['review'] = df['리뷰'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', str(x)))\n",
    "\n",
    "# 토큰화 함수 정의\n",
    "def english_tokenizer(text):\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "tfidf = TfidfVectorizer(tokenizer=english_tokenizer, ngram_range=(1, 2), min_df=3, max_df=0.9)\n",
    "tfidf_matrix = tfidf.fit_transform(df['review'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18591x65123 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1947133 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>숙소_id</th>\n",
       "      <th>리뷰날짜</th>\n",
       "      <th>리뷰</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2104349</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>Strategically positioned apartment (in two lev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>904241734383540468</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>Beautiful place. one bedroom with a bedsofa in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23476199</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>Alexandra's apartment is like a trip back in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>723879972115619669</td>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>Wonderful apartment, felt right at home.  Love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25025384</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>Good place, close to train station! Alex is ve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                숙소_id        리뷰날짜  \\\n",
       "0             2104349  2019-03-03   \n",
       "1  904241734383540468  2023-09-09   \n",
       "2            23476199  2018-05-29   \n",
       "3  723879972115619669  2022-12-02   \n",
       "4            25025384  2022-04-29   \n",
       "\n",
       "                                                  리뷰  \n",
       "0  Strategically positioned apartment (in two lev...  \n",
       "1  Beautiful place. one bedroom with a bedsofa in...  \n",
       "2  Alexandra's apartment is like a trip back in t...  \n",
       "3  Wonderful apartment, felt right at home.  Love...  \n",
       "4  Good place, close to train station! Alex is ve...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ciw96\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 긍정적 리뷰와 부정적 리뷰로 분류\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m positive_reviews \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m전체\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m리뷰\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     11\u001b[0m negative_reviews \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m전체\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.05\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m리뷰\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 영어, 스페인어, 독일어 불용어 목록 결합 및 리스트로 변환\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# nltk 데이터 다운로드 (첫 실행 시 필요)\n",
    "nltk.download('stopwords')\n",
    "print(type(stopwords.words('english')))\n",
    "# 긍정적 리뷰와 부정적 리뷰로 분류\n",
    "positive_reviews = df[df['전체'] >= 0.05]['리뷰'].dropna().astype(str)\n",
    "negative_reviews = df[df['전체'] <= -0.05]['리뷰'].dropna().astype(str)\n",
    "\n",
    "# 영어, 스페인어, 독일어 불용어 목록 결합 및 리스트로 변환\n",
    "stop_words = list(set(stopwords.words('english')) | set(stopwords.words('spanish')) | set(stopwords.words('german')))\n",
    "\n",
    "# 추가로 제외할 단어 목록\n",
    "additional_stop_words =  ['paris','super','perfect','place', 'stay', 'airbnb', 'would', 'us','great','nice','good','amazing','highly']\n",
    "\n",
    "# 추가적인 불용어 목록을 결합\n",
    "stop_words.extend(additional_stop_words)\n",
    "\n",
    "# TF-IDF 벡터라이저 초기화 (결합된 불용어 목록 사용)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100, stop_words=stop_words)\n",
    "\n",
    "# 긍정적 리뷰에 대한 TF-IDF 행렬 계산\n",
    "tfidf_matrix_positive = tfidf_vectorizer.fit_transform(positive_reviews)\n",
    "feature_names_positive = tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_scores_positive = tfidf_matrix_positive.sum(axis=0).A1\n",
    "tfidf_df_positive = pd.DataFrame({'word': feature_names_positive, 'tfidf_score': tfidf_scores_positive})\n",
    "top_tfidf_positive = tfidf_df_positive.nlargest(20, 'tfidf_score')  # 상위 20개 단어\n",
    "\n",
    "# 부정적 리뷰에 대한 TF-IDF 행렬 계산 (불용어 목록 조정)\n",
    "try:\n",
    "    tfidf_matrix_negative = tfidf_vectorizer.fit_transform(negative_reviews)\n",
    "    feature_names_negative = tfidf_vectorizer.get_feature_names_out()\n",
    "    tfidf_scores_negative = tfidf_matrix_negative.sum(axis=0).A1\n",
    "    tfidf_df_negative = pd.DataFrame({'word': feature_names_negative, 'tfidf_score': tfidf_scores_negative})\n",
    "    top_tfidf_negative = tfidf_df_negative.nlargest(20, 'tfidf_score')  # 상위 20개 단어\n",
    "\n",
    "    # 결과 출력\n",
    "    print(\"긍정적인 리뷰에서 상위 20개 단어:\")\n",
    "    print(top_tfidf_positive)\n",
    "except ValueError as e:\n",
    "    print(f\"TF-IDF 계산 중 오류 발생: {e}\")\n",
    "    print(\"부정적 리뷰의 예시:\")\n",
    "    print(negative_reviews.head(10))  # 부정적 리뷰 예시 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "부정적인 리뷰에서 상위 20개 단어:\n",
      "         word  tfidf_score\n",
      "1   apartment   925.126654\n",
      "52   location   632.267834\n",
      "37       host   578.785336\n",
      "74       room   474.600973\n",
      "64        one   432.086472\n",
      "11        bed   414.898306\n",
      "16      check   409.445395\n",
      "78      small   392.384281\n",
      "17      clean   378.955139\n",
      "61      night   367.834685\n",
      "10   bathroom   360.023696\n",
      "76     shower   345.391763\n",
      "87       time   334.820329\n",
      "34        get   333.058021\n",
      "24      dirty   331.416706\n",
      "72     really   314.275127\n",
      "32      floor   302.532662\n",
      "25       door   297.347049\n",
      "31       flat   293.504640\n",
      "56      metro   292.095416\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n부정적인 리뷰에서 상위 20개 단어:\")\n",
    "print(top_tfidf_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\ciw96\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: gensim in c:\\users\\ciw96\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\ciw96\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scipy) (1.26.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ciw96\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\ciw96\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scipy gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 리뷰에서 공통적으로 상위에 있는 단어:\n",
      "['host', 'easy', 'close', 'apartment', 'metro', 'restaurants', 'recommend', 'well', 'everything', 'location', 'really', 'lovely', 'comfortable', 'clean']\n",
      "\n",
      "부정적인 리뷰에서 공통적으로 상위에 있는 단어:\n",
      "['host', 'check', 'door', 'apartment', 'location', 'shower', 'room', 'night', 'bathroom', 'small', 'time', 'get', 'bed', 'one']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# 1. Term Frequency (단어 빈도)\n",
    "def term_frequency(reviews, stop_words):\n",
    "    words = [word for word in ' '.join(reviews).split() if word.lower() not in stop_words]\n",
    "    word_counts = Counter(words)\n",
    "    return [word for word, _ in word_counts.most_common(20)]\n",
    "\n",
    "most_common_positive = term_frequency(positive_reviews, stop_words)\n",
    "most_common_negative = term_frequency(negative_reviews, stop_words)\n",
    "\n",
    "# 2. Latent Dirichlet Allocation (LDA)\n",
    "def lda_keywords(reviews, stop_words):\n",
    "    count_vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "    count_data = count_vectorizer.fit_transform(reviews)\n",
    "    lda = LatentDirichletAllocation(n_components=1, random_state=42)\n",
    "    lda.fit(count_data)\n",
    "    topic = lda.components_\n",
    "    feature_names = count_vectorizer.get_feature_names_out()\n",
    "    top_words = [feature_names[i] for i in topic[0].argsort()[-20:]]\n",
    "    return top_words\n",
    "\n",
    "top_words_positive_lda = lda_keywords(positive_reviews, stop_words)\n",
    "top_words_negative_lda = lda_keywords(negative_reviews, stop_words)\n",
    "\n",
    "# 3. TextRank\n",
    "def textrank_keywords(texts, stop_words, top_n=20):\n",
    "    vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # 단어 간의 유사성 그래프 생성\n",
    "    similarity_graph = (X.T * X)\n",
    "    similarity_graph.setdiag(0)\n",
    "    similarity_graph = similarity_graph.toarray()\n",
    "    \n",
    "    # 네트워크 그래프 생성\n",
    "    nx_graph = nx.from_numpy_array(similarity_graph)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    \n",
    "    # 점수 기준 상위 단어 추출\n",
    "    ranked_words = sorted(((scores[i], s) for i, s in enumerate(feature_names)), reverse=True)\n",
    "    top_keywords = [word for _, word in ranked_words[:top_n]]\n",
    "    \n",
    "    return top_keywords\n",
    "\n",
    "positive_keywords_textrank = textrank_keywords(positive_reviews, stop_words)\n",
    "negative_keywords_textrank = textrank_keywords(negative_reviews, stop_words)\n",
    "\n",
    "# 4. TF-IDF\n",
    "def tfidf_keywords(reviews, stop_words, top_n=20):\n",
    "    vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "    X = vectorizer.fit_transform(reviews)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    scores = X.sum(axis=0).A1\n",
    "    sorted_indices = scores.argsort()[::-1]\n",
    "    top_keywords = [feature_names[i] for i in sorted_indices[:top_n]]\n",
    "    return top_keywords\n",
    "\n",
    "top_words_positive_tfidf = tfidf_keywords(positive_reviews, stop_words)\n",
    "top_words_negative_tfidf = tfidf_keywords(negative_reviews, stop_words)\n",
    "\n",
    "# 겹치는 단어 찾기\n",
    "def find_common_words(lists):\n",
    "    common_words = set(lists[0])\n",
    "    for lst in lists[1:]:\n",
    "        common_words.intersection_update(lst)\n",
    "    return list(common_words)\n",
    "\n",
    "positive_lists = [most_common_positive, top_words_positive_lda, positive_keywords_textrank, top_words_positive_tfidf]\n",
    "negative_lists = [most_common_negative, top_words_negative_lda, negative_keywords_textrank, top_words_negative_tfidf]\n",
    "\n",
    "common_positive_words = find_common_words(positive_lists)\n",
    "common_negative_words = find_common_words(negative_lists)\n",
    "\n",
    "print(\"긍정적인 리뷰에서 공통적으로 상위에 있는 단어:\")\n",
    "print(common_positive_words)\n",
    "\n",
    "print(\"\\n부정적인 리뷰에서 공통적으로 상위에 있는 단어:\")\n",
    "print(common_negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['definitely',\n",
       " 'flat',\n",
       " 'check',\n",
       " 'helpful',\n",
       " 'time',\n",
       " 'walk',\n",
       " 'lovely',\n",
       " 'easy',\n",
       " 'really',\n",
       " 'restaurants',\n",
       " 'comfortable',\n",
       " 'close',\n",
       " 'well',\n",
       " 'recommend',\n",
       " 'everything',\n",
       " 'metro',\n",
       " 'clean',\n",
       " 'host',\n",
       " 'location',\n",
       " 'apartment']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_positive_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dirty',\n",
       " 'metro',\n",
       " 'could',\n",
       " 'people',\n",
       " 'clean',\n",
       " 'door',\n",
       " 'floor',\n",
       " 'time',\n",
       " 'small',\n",
       " 'check',\n",
       " 'two',\n",
       " 'get',\n",
       " 'bathroom',\n",
       " 'bed',\n",
       " 'night',\n",
       " 'room',\n",
       " 'one',\n",
       " 'location',\n",
       " 'host',\n",
       " 'apartment']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_negative_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Great location and great places to eat nearby....\n",
       "1        It is a lovely small apartment, very quite and...\n",
       "3        Wonderful apartment in a central, exciting nei...\n",
       "4        One of the best airbnbs we have ever stayed in...\n",
       "5        Eleonor is a really great, responsive host.  T...\n",
       "                               ...                        \n",
       "19995                           Great stay, great location\n",
       "19996    We spent a lot of time exploring Paris and aft...\n",
       "19997    Apartment was very nice and comfortable. All w...\n",
       "19998    Very cute well designed use of a small space. ...\n",
       "19999    Very nice apartment in a comparatively quiet n...\n",
       "Name: 리뷰, Length: 19517, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2        The appartement was fine, close to the metro s...\n",
       "156      I had a horrible experience at this place. I r...\n",
       "169      Vincent strikes me as someone who is tired of ...\n",
       "479      One key for 8 people. Poor 4 rolls of tp for 8...\n",
       "481      Good location.  Good size apartment, however w...\n",
       "                               ...                        \n",
       "19823    The apartment is unique and in a great locatio...\n",
       "19831        good place but the sound proof is not perfect\n",
       "19845    Everything was great. Clean and nice little pl...\n",
       "19886    It is a dirty place, I think they never clean ...\n",
       "19923    Love the hotel (amazing value for money) but h...\n",
       "Name: 리뷰, Length: 305, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpora' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 사전 생성\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dictionary \u001b[38;5;241m=\u001b[39m \u001b[43mcorpora\u001b[49m\u001b[38;5;241m.\u001b[39mDictionary(texts)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 말뭉치 생성\u001b[39;00m\n\u001b[0;32m      5\u001b[0m corpus \u001b[38;5;241m=\u001b[39m [dictionary\u001b[38;5;241m.\u001b[39mdoc2bow(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpora' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
